import torch.nn as nn

class Head(nn.module):

    def __init__(self,):
        # super

    def forward(self, x, t, prop=None):
        # need to define standard way of performing message passing

        return ( (type_b, type_eta), (coord_b, coord_eta), (lattice_b, lattice_eta) ) 
